{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SWOT data acquisition\n",
    "\n",
    "#### Jonas Felipe Santos de Souza (jonas.ssouza@ufpe.br)\n",
    "\n",
    "#### Federal University of Pernambuco\n",
    "\n",
    "#### June 10, 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"><b>IMPORTANT:</b> check if the libraries below are installed.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipyleaflet import Map, DrawControl, GeoJSON, Popup, Rectangle\n",
    "from shapely.geometry import Polygon\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import HTML\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import earthaccess\n",
    "import warnings\n",
    "import zipfile\n",
    "import time\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN DIRECTORY\n",
    "inpath = 'C:/Users/crist/Desktop/Doctorado/paper/SWOT/swot_rivers/'\n",
    "\n",
    "# Path to save the obtained products\n",
    "swotpath = f'{inpath}products/' # *.zip\n",
    "\n",
    "# SWOT ID of river sections (*.csv file)\n",
    "swot_id = f'{inpath}reachesidv17biobio.csv'\n",
    "\n",
    "# Path to save SWOT data after extraction\n",
    "swot_data = f'{inpath}River_SP_v17/reaches/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## River_SP SWOT database acquisition\n",
    "\n",
    "The database must be obtained from the *hydroweb.next* platform (https://hydroweb.next.theia-land.fr/).\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\"><b>SKIP THIS STEP IF YOU ALREADY HAVE THE DATABASE YOU ARE INTERESTED IN.</b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help_message = \"\"\"\n",
    "Download products from your hydroweb.next projects (https://hydroweb.next.theia-land.fr) using the py-hydroweb lib (https://pypi.org/project/py-hydroweb/)\n",
    "This script is an example tuned for your last hydroweb.next project but feel free to adapt it for future requests.\n",
    "Follow these steps:\n",
    "1. If not already done, install py-hydroweb latest version using `pip install -U py-hydroweb` (WARNING: python >= 3.8 is required)\n",
    "2a. Generate an API-Key from hydroweb.next portal in your user settings\n",
    "2b. Carefully store your API-Key (2 options):\n",
    "- either in an environment variable `export HYDROWEB_API_KEY=\"<your_key_here>\"`\n",
    "- or in below script by replacing <your_key_here>\n",
    "3. You can change download directory by adding an `output_folder` parameter when calling `submit_and_download_zip` (see below). By default, current path is used.\n",
    "4. You are all set, run this script `python download_script.py`\n",
    "\n",
    "For more documentation about how to use the py-hydroweb lib, please refer to https://pypi.org/project/py-hydroweb/.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from importlib.metadata import version\n",
    "\n",
    "try:\n",
    "    import py_hydroweb\n",
    "except ImportError:\n",
    "    print(help_message)\n",
    "    exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check py-hydroweb version\n",
    "latest_version = \"1.0.2\"\n",
    "if version(\"py_hydroweb\") < latest_version:\n",
    "    logging.getLogger().warning(f\"\"\"\\033[33m\n",
    "/!\\ Consider upgrading py-hydroweb to {latest_version} using `pip install -U py-hydroweb`\n",
    "\\033[0m\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set log config\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"><b>IMPORTANT:</b> Check in your hydroweb.next account if the <b>API key</b> has been generated and is active.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API key\n",
    "api_hydroweb = \"ICx9VJ6BM672ed61TIqHXDzwwtZRecK15AnYi9VlNF0ubKn5n9\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a client\n",
    "#  - either using the API-Key environment variable (HYDROWEB_API_KEY)\n",
    "#client: py_hydroweb.Client = py_hydroweb.Client(\"https://hydroweb.next.theia-land.fr/api\")\n",
    "#  - or explicitly giving API-Key (comment line above and uncomment line below)\n",
    "client: py_hydroweb.Client = py_hydroweb.Client(\"https://hydroweb.next.theia-land.fr/api\", \n",
    "                                                api_key=api_hydroweb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate a new download basket (input the name you want here)\n",
    "basket: py_hydroweb.DownloadBasket = py_hydroweb.DownloadBasket(\"my_download_basket\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add collections in our basket\n",
    "# inserir no campo bbox as coordenadas da região de interesse\n",
    "# \"SWOT_PRIOR_RIVER_DATABASE\"\n",
    "# \"SWOT_PRIOR_LAKE_DATABASE\"\n",
    "basket.add_collection(\"SWOT_PRIOR_RIVER_DATABASE\", \n",
    "        #bbox=[-41.40, -9.60, -34.74, -7.10])\n",
    "        bbox=[-74.091797, -38.894373, -70.378418, -36.300877])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do download (input the archive name you want here, and optionally an output folder)\n",
    "now = datetime.today().strftime(\"%Y%m%dT%H%M%S\")\n",
    "downloaded_zip_path: str = client.submit_and_download_zip(\n",
    "    basket,\n",
    "    zip_filename=f\"{inpath}my_hydroweb_data_{now}.zip\",\n",
    "    #, output_folder = \"<change_me>\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## SWOT product search data configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shapefile with reaches river\n",
    "# This file should be obtained from the SWOT database at hydroweb.next\n",
    "shp = f'{inpath}SWOT_PRIOR_RIVER_DATABASE/sa_sword_reaches_hb66_v17.shp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dados para busca dos produtos SWOT\n",
    "# 'SWOT_L2_HR_LakeSP_Prior_2.0', 'SWOT_L2_HR_RiverSP_Reach_2.0', 'SWOT_L2_HR_Raster_100m_2.0'\n",
    "swot_product = 'SWOT_L2_HR_RiverSP_Reach_2.0'\n",
    "short_product = 'SWOT_RiverSP' # 'SWOT_LakeSP', 'SWOT_Raster', 'SWOT_RiverSP'\n",
    "date_start = '2024-01-01'\n",
    "date_end = '2024-12-31'\n",
    "granule_product = '*'\n",
    "\n",
    "# Plot graphs\n",
    "ifplot = True # True or False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Map for selecting the area of ​​interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Compatibility helper for environments without Jupyter widget support\n",
    "def show_map_with_fallback(map_widget, fallback_file='swot_map_fallback.html'):\n",
    "    \"\"\"\n",
    "    Show ipyleaflet when widgets are available and ALWAYS render\n",
    "    a folium interactive fallback in the same notebook output.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        display(map_widget)\n",
    "        print(\"If the map above shows 'Error displaying widget: model not found', use the fallback map below.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Interactive widget could not be displayed: {e}\")\n",
    "\n",
    "    try:\n",
    "        import folium\n",
    "        from IPython.display import HTML\n",
    "\n",
    "        # Build a widget-independent interactive fallback\n",
    "        fmap = folium.Map(location=list(map_widget.center), zoom_start=int(map_widget.zoom), control_scale=True)\n",
    "\n",
    "        # Draw selected area if available\n",
    "        if polygon is not None:\n",
    "            folium.GeoJson(\n",
    "                data={'type': 'Feature', 'geometry': polygon.__geo_interface__},\n",
    "                name='selected_area',\n",
    "                style_function=lambda _: {'color': '#1f77b4', 'weight': 2, 'fillOpacity': 0.1}\n",
    "            ).add_to(fmap)\n",
    "\n",
    "        # Draw filtered SWOT features if available\n",
    "        if geojson_layer is not None and getattr(geojson_layer, 'data', None):\n",
    "            folium.GeoJson(\n",
    "                data=geojson_layer.data,\n",
    "                name='filtered_features',\n",
    "                style_function=lambda _: {'color': 'green', 'weight': 2, 'fillOpacity': 0.2},\n",
    "                tooltip=folium.GeoJsonTooltip(fields=['reach_id'], aliases=['Reach ID'], localize=True, sticky=False)\n",
    "            ).add_to(fmap)\n",
    "\n",
    "        folium.LayerControl(collapsed=False).add_to(fmap)\n",
    "        fmap.save(fallback_file)\n",
    "\n",
    "        # Display fallback inline in the same script output\n",
    "        display(HTML(fmap._repr_html_()))\n",
    "        print(f\"Fallback map rendered inline and saved to: {fallback_file}\")\n",
    "    except Exception as fallback_error:\n",
    "        print(f\"Fallback rendering failed: {fallback_error}\")\n",
    "        print(\"Install folium in this kernel/environment: pip install folium\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive map + HTML fallback for environments without widget support\n",
    "show_map_with_fallback(m)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Login and search for SWOT products in the *EarthData* database\n",
    "\n",
    "You need to have an EarthData account (https://urs.earthdata.nasa.gov/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"><b>IMPORTANT:</b> Please make sure your EarthData account login and password are correct. </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polygon.bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Verificar se o polígono foi desenhado\n",
    "if 'polygon' in globals():   \n",
    "    # Earthdata login\n",
    "    earthaccess.login()\n",
    "    \n",
    "    # Buscar dados dentro dos limites do polígono\n",
    "    results = earthaccess.search_data(short_name = swot_product,\n",
    "                                      temporal = (date_start, date_end),\n",
    "                                      #granule_name=granule_product,\n",
    "                                      bounding_box=(polygon.bounds))\n",
    "    \n",
    "    # Exibir os granules encontrados\n",
    "    items = [item['meta']['native-id'] for item in results]\n",
    "    #print(f\"Granules encontrados: {items}\")\n",
    "else:\n",
    "    print(\"Nenhum polígono foi desenhado.\")\n",
    "\n",
    "# Display the granules found\n",
    "print(len(items))\n",
    "print(items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## SWOT data download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function to download a file and retry if necessary\n",
    "def download_file_with_retries(file_url, download_path, max_retries=3):\n",
    "    attempts = 0\n",
    "    success = False\n",
    "\n",
    "    while attempts < max_retries and not success:\n",
    "        try:\n",
    "            earthaccess.download(file_url, download_path)\n",
    "            file = max(Path(download_path).glob('SWOT*.zip'), key=os.path.getmtime)\n",
    "            if file.exists() and file.stat().st_size > 0:\n",
    "                success = True\n",
    "                print(f\"Successfully downloaded: {file}\")\n",
    "            else:\n",
    "                raise Exception(\"File downloaded but appears to be incomplete.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempts + 1} failed: {e}\")\n",
    "            attempts += 1\n",
    "            time.sleep(5)  # Wait for 5 seconds before retrying\n",
    "            # Clean up the incomplete file\n",
    "    if not success:\n",
    "        print(f\"Failed to download file after {max_retries} attempts.\")\n",
    "\n",
    "# Set the download directory and file URL (list of URLs in this example)\n",
    "file_urls = results[:500]  # Replace with your actual list of file URLs\n",
    "\n",
    "# Download files with retries\n",
    "for file_url in file_urls:\n",
    "    download_file_with_retries(file_url, swotpath)\n",
    "\n",
    "# Check the most recent file in the download directory\n",
    "files = glob.glob(swotpath + 'SWOT*.zip')\n",
    "try:\n",
    "    file = max(files, key=os.path.getmtime)\n",
    "    print(f\"\\nThe most recent file is: {file}\")\n",
    "    #assert file.exists()\n",
    "except ValueError:\n",
    "    print(\"\\nNo files were downloaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Capturing data of interest from downloaded SWOT products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"><b>IMPORTANT:</b> It will help if you have a *.csv file with data on the sections of the rivers of interest (name, reaches SWOT ID etc.).</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *.csv file with SWOT IDs of rivers\n",
    "reachid = pd.read_csv(swot_id, sep=';', decimal=',')\n",
    "reachid['reach ID'] = reachid['reach ID'].astype(str)\n",
    "reachid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set the directory containing the zipped shapefiles\n",
    "zip_dir = swotpath\n",
    "output_dir = swot_data\n",
    "\n",
    "for i in range(len(reachid.index)):\n",
    "    # Define the target reach_id and other conditions\n",
    "    target_reach_id = reachid['reach ID'][i]\n",
    "    #target_reach_id = '62281100021'\n",
    "    valid_reach_q = [0, 1]\n",
    "\n",
    "    # Lists to store the data\n",
    "    records = []\n",
    "\n",
    "    # Loop over all ZIP files in the directory\n",
    "    for filename in os.listdir(zip_dir):\n",
    "        if filename.endswith(\".zip\") and \"Reach\" in filename:\n",
    "            zip_path = os.path.join(zip_dir, filename)\n",
    "            \n",
    "            with zipfile.ZipFile(zip_path, 'r') as z:\n",
    "                # Extract all the shapefile components (shp, shx, dbf, etc.)\n",
    "                z.extractall(\"temp_shapefile\")  # Temporary folder to hold unzipped files\n",
    "                shapefile_path = [f for f in os.listdir(\"temp_shapefile\") if f.endswith(\".shp\")][0]\n",
    "                shapefile_full_path = os.path.join(\"temp_shapefile\", shapefile_path)\n",
    "                \n",
    "                # Load the shapefile into a GeoDataFrame\n",
    "                gdf = gpd.read_file(shapefile_full_path)\n",
    "\n",
    "                # Mapeo case-insensitive de columnas\n",
    "                cols = {c.lower(): c for c in gdf.columns}\n",
    "                reach_id_col  = cols.get('reach_id')\n",
    "                reach_q_col   = cols.get('reach_q')\n",
    "                time_col      = cols.get('time_str') or cols.get('time')\n",
    "                wse_col       = cols.get('wse')\n",
    "                wse_u_col     = cols.get('wse_u')\n",
    "                slope_col     = cols.get('slope')\n",
    "                slope_u_col   = cols.get('slope_u')\n",
    "                width_col     = cols.get('width')\n",
    "                width_u_col   = cols.get('width_u')\n",
    "                area_total_col= cols.get('area_total')\n",
    "                area_detct_col= cols.get('area_detct')\n",
    "                area_tot_u_col= cols.get('area_tot_u')\n",
    "                area_det_u_col= cols.get('area_det_u')\n",
    "\n",
    "                if not (reach_id_col and reach_q_col and time_col and wse_col):\n",
    "                    # Clean up the temporary folder\n",
    "                    for f in os.listdir(\"temp_shapefile\"):\n",
    "                        os.remove(os.path.join(\"temp_shapefile\", f))\n",
    "                    continue\n",
    "                \n",
    "                # Filter the data based on reach_id and reach_q\n",
    "                filtered_gdf = gdf[(gdf[reach_id_col] == target_reach_id) & (gdf[reach_q_col].isin(valid_reach_q))].copy()\n",
    "                \n",
    "                # Extract variables\n",
    "                if not filtered_gdf.empty:\n",
    "                    filtered_gdf['Date'] = pd.to_datetime(filtered_gdf[time_col], errors='coerce')\n",
    "                    filtered_gdf['wse'] = pd.to_numeric(filtered_gdf[wse_col], errors='coerce')\n",
    "\n",
    "                    extra_map = {\n",
    "                        'wse_u': wse_u_col,\n",
    "                        'slope': slope_col,\n",
    "                        'slope_u': slope_u_col,\n",
    "                        'width': width_col,\n",
    "                        'width_u': width_u_col,\n",
    "                        'area_total': area_total_col,\n",
    "                        'area_detct': area_detct_col,\n",
    "                        'area_tot_u': area_tot_u_col,\n",
    "                        'area_det_u': area_det_u_col,\n",
    "                    }\n",
    "\n",
    "                    for out_col, in_col in extra_map.items():\n",
    "                        if in_col:\n",
    "                            filtered_gdf[out_col] = pd.to_numeric(filtered_gdf[in_col], errors='coerce')\n",
    "                        else:\n",
    "                            filtered_gdf[out_col] = pd.NA\n",
    "\n",
    "                    filtered_gdf = filtered_gdf.dropna(subset=['Date', 'wse'])\n",
    "\n",
    "                    for row in filtered_gdf[['Date', 'wse', 'wse_u', 'slope', 'slope_u', 'width', 'width_u', 'area_total', 'area_detct', 'area_tot_u', 'area_det_u']].itertuples(index=False, name=None):\n",
    "                        records.append(row)\n",
    "            \n",
    "                # Clean up the temporary folder\n",
    "                for f in os.listdir(\"temp_shapefile\"):\n",
    "                    os.remove(os.path.join(\"temp_shapefile\", f))\n",
    "    \n",
    "    # Check if data was found\n",
    "    if records:\n",
    "        # Sort the values by time\n",
    "        records.sort(key=lambda x: x[0])\n",
    "        \n",
    "        # Step to save data to a CSV file\n",
    "        df = pd.DataFrame(\n",
    "            records,\n",
    "            columns=['Date', 'wse', 'wse_u', 'slope', 'slope_u', 'width', 'width_u', 'area_total', 'area_detct', 'area_tot_u', 'area_det_u']\n",
    "        )\n",
    "    \n",
    "        # Save DataFrame to CSV, using the reach_id as the filename\n",
    "        output_csv = os.path.join(output_dir, f'{target_reach_id}_{short_product}.csv')\n",
    "        df.to_csv(output_csv, sep=',', decimal='.', encoding='utf-8', index=False)\n",
    "        print(f\"Data saved to {output_csv}\")\n",
    "\n",
    "        if ifplot == True:\n",
    "            # Plotting\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(df['Date'], df['wse'], marker='o', linestyle='-')\n",
    "            plt.xlabel('Date')\n",
    "            plt.ylabel('WSE (m) EGM08')\n",
    "            plt.title(f'WSE over Time for Reach ID: {target_reach_id}')\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    \n",
    "    else:\n",
    "        print(f\"No data found for reach_id {target_reach_id}.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}